{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"YPASsgIoizvI"},"outputs":[],"source":["import locale\n","def getpreferredencoding(do_setlocale = True):\n","    return \"UTF-8\"\n","locale.getpreferredencoding = getpreferredencoding\n","\n","!pip -q install datasets\n","!pip -q install transformers\n","!pip -q install peft\n","!pip -q install -U bitsandbytes"]},{"cell_type":"code","source":["from transformers import (\n","    AutoTokenizer,\n","    AutoModelForCausalLM,\n","    BitsAndBytesConfig,\n",")\n","\n","import torch\n","import os\n","\n","from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"hcOEfU-1kDRh","executionInfo":{"status":"ok","timestamp":1702097173565,"user_tz":300,"elapsed":9535,"user":{"displayName":"colabpro gatechmscs","userId":"12293304342394863693"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["def get_model_size(model):\n","    torch.save(model.state_dict(), \"temp_model.pth\")\n","    size_mb = os.path.getsize(\"temp_model.pth\") / (1024 ** 3)\n","    os.remove(\"temp_model.pth\")\n","    return size_mb\n","\n","def get_num_trainable_parameters(model):\n","    num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","    return num_params\n","\n","def get_lora_config(target_modules):\n","    return LoraConfig(\n","        r=8,\n","        target_modules=target_modules,\n","        lora_alpha=32,\n","        lora_dropout=0.05,\n","        bias=\"none\",\n","        task_type=\"CAUSAL_LM\",\n","    )\n","\n","def compute_model_sizes(model_name, quantization_enabled=False, lora_config=None):\n","    model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True)\n","\n","    if lora_config:\n","        params_before_lora = get_num_trainable_parameters(model)\n","        print(f\"Num trainable before Lora: {params_before_lora}\")\n","\n","        lora_model = prepare_model_for_kbit_training(model)\n","        lora_model = get_peft_model(lora_model, lora_config)\n","        params_after_lora = get_num_trainable_parameters(lora_model)\n","        print(f\"Num trainable after Lora: {params_after_lora}\")\n","        print(f\"% of all params: {(params_after_lora / params_before_lora):.6f}\")\n","\n","    if quantization_enabled:\n","        quant_config = BitsAndBytesConfig(\n","            load_in_4bit=True,\n","            bnb_4bit_use_double_quant=True,\n","            bnb_4bit_quant_type=\"nf4\",\n","            bnb_4bit_compute_dtype=torch.bfloat16,\n","        )\n","        quant_model = AutoModelForCausalLM.from_pretrained(\n","            model_name, quantization_config=quant_config, device_map={\"\": 0}, trust_remote_code=True\n","        )\n","        size_before_quantization = get_model_size(model)\n","        size_after_quantization = get_model_size(quant_model)\n","        print(f\"Size before quantization: {size_before_quantization:.4f} GB\")\n","        print(f\"Size after quantization: {size_after_quantization:.4f} GB\")\n","        return\n","\n","    # If quantization is not enabled\n","    size = get_model_size(model)\n","    print(f\"Model size without quantization: {size:.4f} GB\")\n","\n","    return"],"metadata":{"id":"vcPRk1fJkyCA","executionInfo":{"status":"ok","timestamp":1702097173566,"user_tz":300,"elapsed":7,"user":{"displayName":"colabpro gatechmscs","userId":"12293304342394863693"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Results for CodeParrot Small\n","model_name = \"codeparrot/codeparrot-small\"\n","target_modules=[\"c_attn\", \"c_proj\", \"c_fc\"]\n","lora_config = get_lora_config(target_modules)\n","\n","compute_model_sizes(model_name, quantization_enabled=True, lora_config=lora_config)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N3J6PPmZwREQ","executionInfo":{"status":"ok","timestamp":1702096747346,"user_tz":300,"elapsed":7435,"user":{"displayName":"colabpro gatechmscs","userId":"12293304342394863693"}},"outputId":"38a93157-f4e8-4dbb-e60c-c61936444d7f"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Num trainable before Lora: 111008256\n","Num trainable after Lora: 1179648\n","% of all params: 0.010627\n","Size before quantization: 0.4180 GB\n","Size after quantization: 0.0896 GB\n"]}]},{"cell_type":"code","source":["# Results for CodeParrot Large\n","model_name = \"codeparrot/codeparrot\"\n","target_modules=[\"c_attn\", \"c_proj\", \"c_fc\"]\n","lora_config = get_lora_config(target_modules)\n","\n","compute_model_sizes(model_name, quantization_enabled=True, lora_config=lora_config)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"so_B5ixF2R2H","executionInfo":{"status":"ok","timestamp":1702096720718,"user_tz":300,"elapsed":52545,"user":{"displayName":"colabpro gatechmscs","userId":"12293304342394863693"}},"outputId":"7d9400d0-15f8-429d-e550-d6434cd122b7"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["Num trainable before Lora: 1529628800\n","Num trainable after Lora: 9830400\n","% of all params: 0.006427\n","Size before quantization: 5.7354 GB\n","Size after quantization: 0.8117 GB\n"]}]},{"cell_type":"code","source":["# Results for CodeGen\n","model_name = \"Salesforce/codegen-2B-mono\"\n","target_modules=[\"qkv_proj\", \"out_proj\", \"fc_in\", \"fc_out\"]\n","lora_config = get_lora_config(target_modules)\n","\n","compute_model_sizes(model_name, quantization_enabled=True, lora_config=lora_config)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pwfMuuRqmsyE","outputId":"54d0b99d-7c1f-4162-875e-723d85ea6823","executionInfo":{"status":"ok","timestamp":1702097286940,"user_tz":300,"elapsed":113378,"user":{"displayName":"colabpro gatechmscs","userId":"12293304342394863693"}}},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Num trainable before Lora: 2779356160\n","Num trainable after Lora: 10485760\n","% of all params: 0.003773\n","Size before quantization: 10.3932 GB\n","Size after quantization: 1.6990 GB\n"]}]},{"cell_type":"code","source":["# Results for DeciCoder\n","model_name = \"Deci/DeciCoder-1b\"\n","target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n","lora_config = get_lora_config(target_modules)\n","\n","compute_model_sizes(model_name, quantization_enabled=True, lora_config=lora_config)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sir0mqwA0sw4","executionInfo":{"status":"ok","timestamp":1702097324606,"user_tz":300,"elapsed":37672,"user":{"displayName":"colabpro gatechmscs","userId":"12293304342394863693"}},"outputId":"0c28bd74-a450-40c3-db83-ab53d1ec65ed"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Num trainable before Lora: 1113671680\n","Num trainable after Lora: 5857280\n","% of all params: 0.005259\n","Size before quantization: 4.1708 GB\n","Size after quantization: 0.8139 GB\n"]}]}]}